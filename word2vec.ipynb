{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from random import random\n",
    "import math\n",
    "from collections import OrderedDict,Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_tokens(path):\n",
    "    with open(path, 'r') as fp:\n",
    "        buf = []\n",
    "        while True:\n",
    "            ch = fp.read(1)\n",
    "            if ch == '':\n",
    "                break\n",
    "            elif ch.isspace():\n",
    "                if buf:\n",
    "                    yield ''.join(buf)\n",
    "                    buf = []\n",
    "            else:\n",
    "                buf.append(ch)\n",
    "\n",
    "def generate_tokens_ch(path):\n",
    "    for w in generate_tokens(path):\n",
    "        yield w.decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wcount = Counter(generate_tokens_ch(\"poem.txt\"))\n",
    "word_dict = OrderedDict(sorted(wcount.items(), reverse=True, key=lambda x:x[1]))\n",
    "fj = open(\"w2v_dict_poem.json\", \"w\")\n",
    "fj.write(json.dumps(word_dict, indent=4))\n",
    "fj.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_vocab = 3000\n",
    "word_dict_list = sorted(word_dict.items(),reverse=True, key=lambda x:x[1])[:s_vocab-1]\n",
    "word_dict = OrderedDict(map(lambda x: (x[1][0], x[0]) ,enumerate(word_dict_list)))\n",
    "f2 = open(\"poem_idx.txt\",\"w\")\n",
    "for w in generate_tokens_ch(\"poem.txt\"):\n",
    "    f2.write(\"%s \"% word_dict.get(w, s_vocab-1))\n",
    "f2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_id_freq_list = map(lambda x: (x[0], x[1][1]) ,enumerate(word_dict_list))\n",
    "negsamp_max_count = max([x[1] for x in word_id_freq_list])\n",
    "word_id_freq_list.append((len(word_dict_list), negsamp_max_count))\n",
    "negsamp_array_size = sum([x[1] for x in word_id_freq_list])\n",
    "negsamp_array = np.zeros(negsamp_array_size).astype(int)\n",
    "offset = 0\n",
    "for witem in word_id_freq_list:\n",
    "    negsamp_array[offset:offset + witem[1]] = witem[0]\n",
    "    offset += witem[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_embed = 30\n",
    "s_window = 3\n",
    "eta_init = 1.\n",
    "rho = 0.8\n",
    "ite = 10\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "count: 10000, eta 0.174740603957\n",
      "avg_err: 0.498393238625\n",
      "count: 20000, eta 0.162511416158\n",
      "avg_err: 0.465046838269\n",
      "count: 30000, eta 0.156119904854\n",
      "avg_err: 0.342064729645\n",
      "count: 40000, eta 0.151881626193\n",
      "avg_err: 0.360685890166\n",
      "count: 50000, eta 0.148749345428\n",
      "avg_err: 0.378291523453\n",
      "count: 60000, eta 0.146284390945\n",
      "avg_err: 0.350175375407\n",
      "count: 70000, eta 0.144263150824\n",
      "avg_err: 0.343263973645\n",
      "count: 80000, eta 0.142556883985\n",
      "avg_err: 0.325994073362\n",
      "count: 90000, eta 0.141085003853\n",
      "avg_err: 0.314083784991\n",
      "count: 100000, eta 0.139793879444\n",
      "avg_err: 0.305908434273\n",
      "count: 110000, eta 0.138646104479\n",
      "avg_err: 0.300968859986\n",
      "count: 120000, eta 0.137614602125\n",
      "avg_err: 0.300016839212\n",
      "count: 130000, eta 0.136679172915\n",
      "avg_err: 0.299559380643\n",
      "count: 140000, eta 0.13582436701\n",
      "avg_err: 0.293834065939\n",
      "count: 150000, eta 0.135038116289\n",
      "avg_err: 0.296055602717\n",
      "count: 160000, eta 0.134310823367\n",
      "avg_err: 0.294560170406\n",
      "count: 170000, eta 0.133634736416\n",
      "avg_err: 0.289266871915\n",
      "count: 180000, eta 0.133003508905\n",
      "avg_err: 0.282939277436\n",
      "count: 190000, eta 0.132411882523\n",
      "avg_err: 0.279945181439\n",
      "count: 200000, eta 0.13185545424\n",
      "avg_err: 0.277843423303\n",
      "count: 210000, eta 0.131330502189\n",
      "avg_err: 0.276470223567\n",
      "count: 220000, eta 0.130833853445"
     ]
    }
   ],
   "source": [
    "W_emb = (0.5 - np.random.rand(s_vocab, s_embed)) / math.sqrt(s_vocab + s_embed)\n",
    "W_o = (0.5 - np.random.rand(s_embed, s_vocab)) / math.sqrt(s_vocab + s_embed)\n",
    "\n",
    "W_o_rp = 0.1 + np.zeros((s_embed, s_vocab))\n",
    "W_emb_rp = 0.1 + np.zeros((s_vocab, s_embed))\n",
    "\n",
    "context = []\n",
    "toprint = 10000\n",
    "avg_err = 0.\n",
    "w_count = 0\n",
    "for it in range(iter):\n",
    "    print \"iter\", it\n",
    "    # cost = 0\n",
    "    for w in generate_tokens(\"poem_idx.txt\"):\n",
    "        eta = eta_init / math.log((w_count + 2),5)\n",
    "        context.append(int(w))\n",
    "        if len(context) > s_window:\n",
    "            context.pop(0)\n",
    "            i_pos = s_window / 2\n",
    "            i_wid = context[i_pos]\n",
    "            h_err = np.zeros((s_embed))\n",
    "            for negcount in range(s_window + 1):\n",
    "                if negcount == 0:\n",
    "                    o_pos = int(math.floor(s_window * random()))\n",
    "                    o_wid = context[o_pos]\n",
    "                    o_golden = 1\n",
    "                else:\n",
    "                    o_wid = negsamp_array[int(math.floor(random() * negsamp_array_size))]\n",
    "                    while o_wid in context:\n",
    "                        o_wid = negsamp_array[int(math.floor(random() * negsamp_array_size))]\n",
    "                    o_golden = 0\n",
    "                o_pred = 1 / (1 + np.exp(- np.dot(W_emb[i_wid, :], W_o[:, o_wid])))\n",
    "                o_err = o_pred - o_golden\n",
    "                h_err += o_err * W_o[:, o_wid]\n",
    "                W_o[:, o_wid] -= eta * o_err * W_emb[i_wid]\n",
    "                avg_err += abs(o_err)\n",
    "            W_emb[i_wid, :] -= eta * h_err\n",
    "            w_count += 1\n",
    "            if w_count % toprint == 0:\n",
    "                print \"count: %s, eta %s\"  % (w_count,eta) \n",
    "                print \"avg_err: %s\" % ( avg_err / float(toprint * (s_window + 1)) )\n",
    "                avg_err = 0.\n",
    "    model_name = \"w2v_model_%s.json\" % (it)\n",
    "    print \"save model: %s\" %(model_name)\n",
    "    fm = open(model_name, \"w\")\n",
    "    fm.write(json.dumps(W_emb.tolist(), indent=4))\n",
    "    fm.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f2 = open(\"w2v_model_2.json\",\"r\") #\"w2v_result_1.json\"\n",
    "w2v_model = np.array(json.loads(\"\".join(f2.readlines())))\n",
    "f2.close()\n",
    "word_dict_reverse = OrderedDict([(x[1],x[0]) for x in word_dict.items() ])\n",
    "\n",
    "def get_top(word):\n",
    "    dot_result = np.dot(w2v_model, np.expand_dims(w2v_model[word_dict.get(word)],axis=1))\n",
    "    final_result = sorted([(x[0], x[1][0]) for x in enumerate(dot_result)], key=lambda x:x[1], reverse=True)\n",
    "    print word\n",
    "    for x in final_result[:10]:\n",
    "        print word_dict_reverse.get(x[0]),x[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "山\n",
      "山 6.89817657156\n",
      "仞 5.48508210203\n",
      "邙 5.39748526383\n",
      "嶂 5.37567603867\n",
      "峴 5.15190922531\n",
      "巔 5.02733352642\n",
      "巒 5.01471489602\n",
      "岫 4.91171794409\n",
      "瀑 4.76158334431\n",
      "隈 4.72631456419\n",
      "峰\n",
      "峰 5.64263792097\n",
      "仞 5.11608931768\n",
      "嶂 5.05273391601\n",
      "巔 5.04045708199\n",
      "梧 4.84342319956\n",
      "聳 4.74719410906\n",
      "萊 4.67863771074\n",
      "岫 4.57765406941\n",
      "嵯 4.52987783543\n",
      "巒 4.48762491327\n",
      "河\n",
      "河 8.3437007543\n",
      "浸 5.99621961846\n",
      "浙 5.80059411055\n",
      "漳 5.74756745907\n",
      "塞 5.52111699118\n",
      "脈 5.41092866703\n",
      "堤 5.4010228908\n",
      "涇 5.34611187256\n",
      "渭 5.34433910114\n",
      "滔 5.29767971582\n",
      "日\n",
      "日 7.53227209683\n",
      "昨 5.64449264962\n",
      "今 5.26162105001\n",
      "曛 5.2149646021\n",
      "柘 5.09228546713\n",
      "曈 4.9494310479\n",
      "終 4.81157483618\n",
      "暮 4.61797751569\n",
      "夕 4.39978962394\n",
      "噪 4.33253007418\n",
      "母\n",
      "母 7.70722898138\n",
      "阿 5.77156595399\n",
      "父 5.11348880257\n",
      "儂 5.1105969784\n",
      "王 5.01025728547\n",
      "氏 4.66142323047\n",
      "慈 4.58391209858\n",
      "妾 4.34954229719\n",
      "萊 4.30786085723\n",
      "荊 4.25904308548\n"
     ]
    }
   ],
   "source": [
    "get_top(u\"山\")\n",
    "get_top(u\"峰\")\n",
    "get_top(u\"河\")\n",
    "get_top(u\"日\")\n",
    "get_top(u\"母\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_calculated_top(w1, w2, w3):\n",
    "    v1 = w2v_model[word_dict.get(w1)]\n",
    "    v2 = w2v_model[word_dict.get(w2)]\n",
    "    v3 =w2v_model[word_dict.get(w3)]\n",
    "    dot_result = np.dot(w2v_model, np.expand_dims(v1+(v2-v3),axis=1))\n",
    "    final_result = sorted([(x[0], x[1][0]) for x in enumerate(dot_result)], key=lambda x:x[1], reverse=True)\n",
    "    print \"%s + %s - %s\" %(w1,w2,w3)\n",
    "    for x in final_result[:10]:\n",
    "        print word_dict_reverse.get(x[0]),x[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "女 + 父 - 男\n",
      "父 6.89753825887\n",
      "陶 6.02543823868\n",
      "公 5.79068975061\n",
      "邀 5.54295744312\n",
      "訪 5.34483994806\n",
      "馮 5.32571235076\n",
      "崔 5.2276940566\n",
      "漁 5.22450417756\n",
      "女 5.14851257927\n",
      "稚 5.13421773684\n"
     ]
    }
   ],
   "source": [
    "get_calculated_top(u\"女\",u\"父\",u\"男\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
